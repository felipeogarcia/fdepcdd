# Inferência Bayesiana {#inferencia-bayesiana}
O paradigma da *inferência bayesiana* tem suas origens no artigo póstumo de [@bayes1763essay], comunicado por seu amigo Richard Price. As derivações das ideias de Bayes são extensas e profundas matemática e filosoficamente, discutidas por grandes nomes da Ciência em incontáveis livros, artigos e compilações ao longo destes mais de 250 anos. Desta forma entende-se que a melhor abordagem para este material é indicar o estado-da-arte da aplicação bayesiana considerando referências consagradas disponíveis online ou na bilbioteca da PUCRS.

```{exercise}
Assita aos vídeos [The Bayesian Trap](https://www.youtube.com/watch?v=R13BD8qKeTg&vl=en) e [Bayes theorem](https://www.youtube.com/watch?v=HZGCoVF3YvM). Lembre que você pode ativar a legenda (botão CC) e alterar a língua nas configurações (ícone de engrenagem > legendas). $\\$
```

<!-- Na abordagem *bayesiana* a estimação pontual é similar à clássica, mas quando feita por intervalos é chamada (estimação por) *Intervalo de Credibilidade* (IC/ICr). Os testes de hipóteses bayesianos têm o mesmo objetivo dos TH da abordagem clássica, que é decidir se um parâmetro ou conjunto de parâmetros pertencem a $\Theta_0$ ou $\Theta_1$, porém garantindo a não violação do *princípio da verossimilhança*. -->

<!-- ## Softwares -->
Um dos principais motivos dos avanços recentes na pesquisa em estatística bayesiana é a crescente facilidade no acesso a recursos computacionais, tanto de hardware quanto de software. Na linguagem R existem muitas bibliotecas para aplicação bayesiana. O [CRAN Task View](https://cran.r-project.org/web/views/)[^ctv] de [inferência bayesiana](https://cran.r-project.org/view=Bayesian) fornece um compêndio atualizado dos pacotes relacionados ao assunto.

[^ctv]: Segundo a documentação oficial do R, os *CRAN Task Views* ('Visualizadores de Tarefa da Rede Abrangente de Arquivos R', em tradução livre) têm como objetivo fornecer alguma orientação sobre quais pacotes no CRAN são relevantes para tarefas relacionadas a um determinado tópico. Eles fornecem uma breve visão geral dos pacotes incluídos têm como objetivo ter um foco nítido para que seja suficientemente claro quais pacotes devem ser incluídos (ou excluídos) - e não têm a intenção de endossar os "melhores" pacotes para uma determinada tarefa.


<!-- ```{example, bayes} -->
<!-- (Adaptado de [@stone2016bayes])  -->
<!-- ``` -->
<!-- ```{r} -->
<!-- # verossimilhança (likelihood) = prob de de manchas devido à varíola -->
<!-- pSpotsGSmallpox <- 0.9 -->
<!-- # priori = prob de varíola -->
<!-- pSmallpox <- 0.001 -->
<!-- # marginal likelihood = prob of spots. -->
<!-- pSpots <- 0.081 -->
<!-- # find posterior = prob of smallpox given spots.  -->
<!-- pSmallpoxGSpots = pSpotsGSmallpox * pSmallpox / pSpots -->
<!-- s <- sprintf("pSmallpoxGSpots = %.3f", pSmallpoxGSpots) -->
<!-- print(s) -->
<!-- ``` -->


## Princípios de verossimilhança, suficiência e condicionalidade
- Seção 1.6 de [@paulino2003estatistica]  
- Seções 3.3 e 3.4 de [@press2003subjective] (Princípio da verossimilhança)  
- Os fundamentos são discutidos por [@birnbaum1962foundations], [@savage1962foundations] e [@wechsler2008birnbaum]  

Informalmente, o *princípio da verossimilhança* admite que se dois decisores possuem o mesmo grau de conhecimento e a mesma informação sobre $\theta$, ambos devem decidir exatamente da mesma forma a respeito de $\theta$. [@berger1985statistical, p.28][^pv] define da seguinte forma:  

> **Princípio da verossimilhança** Ao fazer inferências ou decisões sobre $\theta$ após observar $x$, todas as informações experimentais relevantes estão contidas na função de verossimilhança para o $x$ observado. Além disso, duas funções de verossimilhança contêm as mesmas informações sobre $\theta$ se forem proporcionais entre si (como funções de $\theta$). 

[^pv]: "*The Likelihood Principle. In making inferences or decisions about $\theta$ after x is observed, all relevant experimental information is contained in the likelihood function for the observed x. Furthermore, two likelihood functions contain the same information about $\theta$ if they are proportional to each other (as functions of $\theta$).*" [@berger1985statistical, p.28]

```{example, pv1}
(Princípio da Verossimilhança 1, adaptado de [@paulino2003estatistica]) Considere uma sucessão de lançamentos de uma moeda, independentes e condicionados por $\theta$, a probabilidade de sair 'cara'. Suponha que seja obtido o resultado $$x  =  \lbrace H,T,H,H,T,T,H,T,T,T  \rbrace,$$ onde $H$: 'cara' e $T$: 'coroa'[^cc]. Este resultado poderia ser obtido de diversos processos experimentais ou regras de parada, como  
- realizar 10 lançamentos, fixados a priori  
- lançar a moeda até aparecerem 6 'coroas'  
- lançar a moeda até aparecerem 3 'coroas' consecutivas  
- lançar a moeda até o jogador ficar saturado, tendo a saturação ocorrido no 10º lançamento

[^cc]: Do Inglês *Head* (cara) e *Tail* (coroa). 

Em qualquer caso a (função de) verossimilhança é proporcional a $\theta^4 \left( 1 - \theta \right)^6$, i.e., a amostra informa quatro sucessos (caras) e seis fracassos (coroas). Assim, adotando-se o princípio da verossimilhança, toda a informação que $x$ pode fornecer sobre $\theta$ encontra-se nesta expressão. Saber qual dos quatro processos experimentais foi utilizado (cada um com um espaço amostral diferente) ou saber qual foi a regra de parada adotada nada tem a acrescentar. Note que a possibilidade de o experimentador parar por seu arbítrio ao considerar o resultado $x$ satisfatório, em nada altera a opinião sobre $\theta$. $\\$
```

```{example, pv2}
(Princípio da Verossimilhança 2, adaptado de [@lindley1976inference] por [@paulino2003estatistica]) Suponha que deseja-se testar a hipótese $H_0 : \theta \le 1/2$ contra  $H_1 : \theta > 1/2$. São contemplados dois processos experimentais:  

- $E_1$: lançar a moeda $n=12$ vezes;  
- $E_2$: lançar a moeda até que apareçam $k=3$ 'caras'

Admita que o resultado observado nas duas experiências foi $x=9$ 'coroas' (portanto 3 'caras'), que é uma particular realização da variável aleatória $X$, que designa o número total de 'coroas' dos experimentos $E_1$ e $E_2$. Para um clássico o nível crítico (ou valor-$p$, a probabilidade de obter $X \ge 9$) da hipótese $H_0 : \theta = 1/2$ difere nos dois casos.  

No caso $E_1$, $X$ tem distribuição binomial -- $X \sim \mathcal{B} \left( 12, \theta \right)$ -- cujo nível crítico é

\begin{equation}
Pr\left( X \geq 9 \bigg\rvert \theta = \dfrac{1}{2} \right) = \binom {12}{9}  \left(  \frac{1}{2} \right) ^{12} + \binom {12}{10} \left(  \frac{1}{2} \right) ^{12} + \binom {12}{11}  \left(  \frac{1}{2} \right) ^{12} + \binom {12}{12} \left( \frac{1}{2} \right) ^{12} \approx 0.0730. \nonumber
(\#eq:pvalue-binom)
\end{equation}

No caso $E_2$, $X$ tem distribuição binomial negativa -- $X \sim \mathcal{BN} \left( 3, 1-\theta \right)$ -- que tem nível crítico

\begin{equation}
Pr\left( X \geq 9 \bigg\rvert \theta = \dfrac{1}{2} \right) = \binom {11}{9}  \left(  \frac{1}{2} \right) ^{12} + \binom {12}{10} \left(  \frac{1}{2} \right) ^{13} +\binom {13}{11}  \left(  \frac{1}{2} \right) ^{14} + \cdots \approx 0.0327. \nonumber
(\#eq:pvalue-nbinom)
\end{equation}

  Logo, se for adotado um limiar de significância de $5 \%$, $H_0$ é rejeitada no caso $E_2$ e não rejeitada em $E_1$. Assumindo o princípio da verossimilhança, as conclusões devem ser idênticas nos dois casos. Em ambos a (função de) verossimilhança é proporcional a $\theta^9 \left( 1 - \theta \right)^3$. De fato, as verossimilhanças em $E_1$ e $E_2$ são

$$L_1 \left( \theta \right| x = 9 ) = \binom {12}{9} \theta^{9} \left( 1-\theta \right) ^{3} = 220 \; \theta^{9} \left( 1-\theta \right)^{3} \propto \theta^{9} \left( 1-\theta \right)^{3}$$

\bigskip

$$L_2 \left( \theta \right| x = 9 ) = \binom {11}{9} \theta^{9} \left( 1-\theta \right) ^{3} = 55 \; \theta^{9} \left( 1-\theta \right)^{3} \propto \theta^{9} \left( 1-\theta \right)^{3}$$
```
```{r, echo=FALSE, eval=FALSE}
n <- 12
x <- 9
p <- x/n
pi0 <- .5
sum(dbinom(9:12,n,pi0))
1-sum(dnbinom(0:8,n-x,pi0))
```

## Distribuição a priori
- Fundamentos abordados no Capítulo 2 de [@paulino2003estatistica] e no Capítulo 5 de [@press2003subjective]  
- [@morris2014web] apresentam uma ferramenta baseada na web para obter distribuições de probabilidade de especialistas
 
## Estimação Pontual
- Seções 8.2 e 8.3 de [@press2003subjective]  
- Seção 3.2 de [@paulino2003estatistica]  
<!-- Assim como na abordagem clássica, a *estimação pontual* sob o prisma bayesiano faz uso de estimadores para calcular estimativas (pontuais) para os parâmetros de interesse. Outro uso das estimativas pontuais é resumir a distribuição a posteriori, conforme veremos a seguir. -->

## (Estimação por) Intervalo/Regiões de Credibilidade
- Seção 8.4 de [@press2003subjective]  
- Seção 3.3 de [@paulino2003estatistica]  
<!-- ### Proporção -->

<!-- ### Média -->

## (Estimação por) Teste de Hipóteses
- Capítulo 9 de [@press2003subjective]  
- Seção 3.4 de [@paulino2003estatistica]  

### Fatores de Bayes
- [@kass1995bayes]   
- Seção 9.5.1 de [@press2003subjective]  
- Seção 3.4.1 de [@paulino2003estatistica]  

### FBST - *Full Bayesian Significance Test*
- Proposta de [@pereira1999evidence] para testar hipóteses precisas (*sharp hypotheses*)  
- Amplamente revisado em [@pereira2008can] e [@pereira2020evalue]

<center><p><a href= "https://www.ime.usp.br/~cpereira/">
<img border = "0" src="https://www.ime.usp.br/~cpereira/fbst.gif" width="500">
</a> </p> </center>
